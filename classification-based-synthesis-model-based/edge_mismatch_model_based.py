"""By running this code, the number of mismatched edges between graphs generated by the NNs and the analytical method
will be computed and saved."""
import os
import numpy as np
import math
import time
import copy
from functools import reduce
from operator import mul
import ray
import psutil
import gc
import tensorflow as tf
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.layers import Dense
from tensorflow.python.keras.layers import deserialize, serialize
from tensorflow.python.keras.saving import saving_utils
import env_pool

def unpack(model, training_config, weights):
    restored_model = deserialize(model)
    if training_config is not None:
        restored_model.compile(
            **saving_utils.compile_args_from_training_config(
                training_config
            )
        )
    restored_model.set_weights(weights)
    return restored_model

# Hotfix function
def make_keras_picklable():

    def __reduce__(self):
        model_metadata = saving_utils.model_metadata(self)
        training_config = model_metadata.get("training_config", None)
        model = serialize(self)
        weights = self.get_weights()
        return (unpack, (model, training_config, weights))

    cls = Model
    cls.__reduce__ = __reduce__


def auto_garbage_collect(pct=60.0):
    if psutil.virtual_memory().percent >= pct:
        gc.collect()

def discrete_sys_size_gen():
    """ This function computes a vector that contains number of
     discrete states for every dimension of state and input spaces."""
    discrete_sys_size = np.zeros(dim_x + dim_u)
    for ii in range(0, dim_x):
        discrete_sys_size[ii] = math.floor((X_range[ii, 1] - X_range[ii, 0] - eta_x[ii]) / eta_x[ii] + 1)
    for ii in range(dim_x, dim_x + dim_u):
        discrete_sys_size[ii] = math.floor(
            (U_range[ii - dim_x, 1] - U_range[ii - dim_x, 0] - eta_u[ii - dim_x]) / eta_u[ii - dim_x] + 1)
    return discrete_sys_size.astype(int)


def NN_structure_TS():
    """Create the model for estimating the transition system."""
    model = Sequential()
    model.add(Dense(40, input_dim=dim_x+dim_u, activation=tf.nn.relu))
    model.add(Dense(160, activation=tf.nn.relu))
    model.add(Dense(160, activation=tf.nn.relu))
    model.add(Dense(160, activation=tf.nn.relu))
    model.add(Dense(160, activation=tf.nn.relu))
    model.add(Dense(160, activation=tf.nn.relu))
    model.add(Dense(160, activation=tf.nn.relu))
    model.add(Dense(160, activation=tf.nn.relu))
    model.add(Dense(160, activation=tf.nn.relu))
    model.add(Dense(500, activation=tf.nn.relu))
    model.add(Dense(800, activation=tf.nn.relu))
    model.add(Dense(nn, activation='linear'))
    return model


def dataset_selector(X, offset, i, length):
    return ray.put(X[offset+i*length:min(offset+(i+1)*length, offset+length)])


def edge_mismatch_counter(inp_filename, out_filename, num_samples, inp_dim, out_dim, NN_TS, FW_or_BW):
    x_tr = np.memmap(inp_filename, dtype='float32', mode='r', shape=(num_samples, inp_dim), offset=0)
    y_tr = np.memmap(out_filename, dtype='float32', mode='r', shape=(num_samples, out_dim), offset=0)
    added_mismatch = 0
    added_reached = 0
    added_num_pairs_to_be_stored = 0
    new_num_transitions = 0
    list_of_state_input_pairs_to_be_stored = []

    NN_TS_id = ray.put(NN_TS)
    for step in range(num_state_inp_pairs // num_tasks_per_step+1):
    #  for step in range(5):
        offset = step*num_tasks_per_step
        num_tasks_in_this_step = min(num_tasks_per_step, num_samples - step * num_tasks_per_step)
        new_mismatch_coded = [single_mismatch_analyzer.remote(i,
                                                              x_tr[offset+i*length:min(offset+(i+1)*length, offset+num_tasks_in_this_step)],
                                                              y_tr[offset+i*length:min(offset+(i+1)*length, offset+num_tasks_in_this_step)],
                                                              NN_TS_id, length, num_tasks_in_this_step)[0]
                              for i in range(0, num_tasks_in_this_step // length+1)]
        new_added_coded = [single_mismatch_analyzer.remote(i,
                                                          x_tr[offset+i*length:min(offset+(i+1)*length, offset+num_tasks_in_this_step)],
                                                              y_tr[offset+i*length:min(offset+(i+1)*length, offset+num_tasks_in_this_step)],
                                                              NN_TS_id, length, num_tasks_in_this_step)[1]
                              for i in range(0, num_tasks_in_this_step // length+1)]
        new_num_pairs_to_be_stored_coded = [single_mismatch_analyzer.remote(i,
                                                          x_tr[offset+i*length:min(offset+(i+1)*length, offset+num_tasks_in_this_step)],
                                                              y_tr[offset+i*length:min(offset+(i+1)*length, offset+num_tasks_in_this_step)],
                                                              NN_TS_id, length, num_tasks_in_this_step)[2]
                              for i in range(0, num_tasks_in_this_step // length+1)]
        new_num_transitions_coded = [single_mismatch_analyzer.remote(i,
                                                          x_tr[offset+i*length:min(offset+(i+1)*length, offset+num_tasks_in_this_step)],
                                                              y_tr[offset+i*length:min(offset+(i+1)*length, offset+num_tasks_in_this_step)],
                                                              NN_TS_id, length, num_tasks_in_this_step)[3]
                              for i in range(0, num_tasks_in_this_step // length+1)]
        list_of_state_input_pairs_to_be_stored_coded = [single_mismatch_analyzer.remote(i,
                                                          x_tr[offset+i*length:min(offset+(i+1)*length, offset+num_tasks_in_this_step)],
                                                              y_tr[offset+i*length:min(offset+(i+1)*length, offset+num_tasks_in_this_step)],
                                                              NN_TS_id, length, num_tasks_in_this_step)[4]
                              for i in range(0, num_tasks_in_this_step // length+1)]
        auto_garbage_collect()
        new_mismatch_decoded = ray.get(new_mismatch_coded)
        new_added_decoded = ray.get(new_added_coded)
        new_num_pairs_to_be_stored_decoded = ray.get(new_num_pairs_to_be_stored_coded)
        new_num_transitions_decoded = ray.get(new_num_transitions_coded)
        list_of_state_input_pairs_to_be_stored_decoded = ray.get(list_of_state_input_pairs_to_be_stored_coded)

        added_mismatch += np.sum(new_mismatch_decoded)
        added_reached += np.sum(new_added_decoded)
        added_num_pairs_to_be_stored += np.sum(new_num_pairs_to_be_stored_decoded)
        new_num_transitions += np.sum(new_num_transitions_decoded)

        counter_ext = 0  # initiate the outer counter which counts until the number of new pairs to be added

        for i in range(num_tasks_in_this_step // length + 1):
            counter_int = len(list_of_state_input_pairs_to_be_stored_decoded[i])
            for j in range(counter_int):
                list_of_state_input_pairs_to_be_stored.append(list_of_state_input_pairs_to_be_stored_decoded[i][j])
                counter_ext += 1
            if counter_ext >= np.sum(new_num_pairs_to_be_stored_decoded):
                break

        auto_garbage_collect()
        del new_mismatch_decoded
        del new_added_decoded
        del new_num_pairs_to_be_stored_decoded
        del new_num_transitions_decoded
        del list_of_state_input_pairs_to_be_stored_decoded
    return added_mismatch, added_reached, added_num_pairs_to_be_stored, new_num_transitions, list_of_state_input_pairs_to_be_stored

@ray.remote(num_returns = 5)
def single_mismatch_analyzer(i, xx, yy, NN_TS, length, num_tasks_in_this_step):
    length_for_this_step = min(length, num_tasks_in_this_step - i * length)
    added_mismatch = 0
    added_reached = 0
    added_num_to_be_stored_pairs = 0
    added_num_of_transitions = 0
    list_of_state_input_pairs_to_be_stored = []
    for _ in range(length_for_this_step):
        s1 = xx[_, :]
        inp = s1[dim_x:dim_x + dim_u]
        # Finding discrete set of states corresponding to the continuous disc (for the analytical solution)
        y_analytical = yy[_, :]
        ind_set_analytical = update_reachable_set(y_analytical)
        ind_tuple_analytical = [tuple(item) for item in ind_set_analytical]
        # Finding discrete set of states corresponding to the continuous disc (for the solution by NN)
        y_NN = np.squeeze(NN_TS(np.array([s1])).numpy())
        ind_set_NN = update_reachable_set(y_NN)
        ind_tuple_NN = [tuple(item) for item in ind_set_NN]
        added_mismatch += len(set(ind_tuple_NN).difference(set(ind_tuple_analytical)))
        added_reached += len(set(ind_tuple_analytical))
        if len(set(ind_tuple_analytical).difference(set(ind_tuple_NN))) > 0:
            state_vec_idx = cell_to_vectorized_ind(s1[0:dim_x], X_range, eta_x, state_space_size, dim_x)
            input_vec_idx = cell_to_vectorized_ind(s1[dim_x:dim_x+dim_u], U_range, eta_u, input_space_size, dim_u)
            idx_to_be_added = np.concatenate((state_vec_idx, input_vec_idx))
            added_num_to_be_stored_pairs += 1
            added_num_of_transitions += len(ind_tuple_analytical)
            list_of_state_input_pairs_to_be_stored.append(idx_to_be_added)
    return [added_mismatch, added_reached, added_num_to_be_stored_pairs, added_num_of_transitions, list_of_state_input_pairs_to_be_stored]


def update_reachable_set(y):
    """Finding discrete set of states corresponding to the continuous disc (for the analytical solution)"""
    reach_high_vec_discrete_analytical = compute_bounds(y)[0]  # np.squeeze(np.minimum(tuple(discrete_sys_size[0:dim_x])-np.ones(dim_x), np.maximum(np.zeros(dim_x), np.floor((s2-radii2-err2-X_range[:, 0])/np.squeeze(eta_x)))))
    reach_low_vec_discrete_analytical = compute_bounds(y)[1]  # np.squeeze(np.minimum(tuple(discrete_sys_size[0:dim_x])-np.ones(dim_x), np.maximum(np.ones(dim_x), np.floor((s2+radii1+err1-X_range[:, 0])/np.squeeze(eta_x)))))
    reach_ind_range = np.zeros((dim_x, 2))
    for ind in range(dim_x):
        reach_ind_range[ind, :] = [reach_low_vec_discrete_analytical[ind], reach_high_vec_discrete_analytical[ind]+1] # Adding 1 is necessary for the next step

    ranges = reach_ind_range.astype(int).tolist()
    operations = reduce(mul, (p[1] - p[0] for p in ranges)) - 1  # No. of reached states - 1
    result = [ii[0] for ii in ranges]  # The first reached state
    pos = len(ranges) - 1  # Set the pointer at the last dimension
    increments = 0
    ind_set = [copy.copy(result)]  # Copying value of the first reached state into ind_set
    while increments < operations:
        if result[pos] == ranges[pos][1] - 1:
            result[pos] = ranges[pos][0]
            pos -= 1  # Set the pointer to the previous dimension
        else:
            result[pos] += 1
            increments += 1
            pos = len(ranges) - 1  # Increment the innermost loop and set the pointer at the last dimension
            ind_set.append(copy.copy(result))

    return ind_set


def compute_bounds(vec):
    ub = np.zeros(dim_x)
    lb = np.zeros(dim_x)
    start_id1 = 0
    for dim in range(dim_x):
        end_id1 = start_id1 + discrete_sys_size[dim] + 3 * shift_no
        ub[dim] = np.argmax(vec[start_id1:end_id1])
        start_id2 = end_id1
        end_id2 = start_id2 + discrete_sys_size[dim] + 3 * shift_no
        lb[dim] = np.argmax(vec[start_id2:end_id2])
        start_id1 = end_id2  #2*(np.sum(discrete_sys_size[0:dim+1])+2*(dim+1)*shift_no)
    return [ub, lb]


def cell_to_vectorized_ind(state_vec, full_range, eta, space_size, dim):
    ind = np.maximum(np.zeros(dim), np.minimum((state_vec - full_range[:, 0])//np.squeeze(eta), space_size))
    return ind


# Setting the parameters
env = env_pool.tora()

X_range = env.X_range  # state-space
U_range = env.U_range  # input space
sample_time = env.sample_time  # sampling time in seconds
eta_x = env.eta_x  # state-space discretization size
eta_u = env.eta_u  # input-space discretization size
shift_no = env.shift_no
# parallelization parameters
length = env.length
num_tasks_per_step = env.num_tasks_per_step
# defining filenames for saving the transition system
forw_inp_TS_filename = env.forw_inp_TS_filename
forw_out_TS_filename = env.forw_out_TS_filename
back_inp_TS_filename = env.back_inp_TS_filename
back_out_TS_filename = env.back_out_TS_filename
# defining paths for saving the trained NNs
checkpoint_path_TS_forw = env.checkpoint_path_TS_forw
checkpoint_path_TS_back = env.checkpoint_path_TS_back
# defining filenames for saving the mismatch edges per state-input pair
mismatch_list_forw_filename = env.mismatch_list_forw_filename
mismatch_list_back_filename = env.mismatch_list_back_filename
num_transitions_forw_filename = env.num_transitions_forw_filename
R_analytical_filename = env.R_analytical_filename
R_NN_filename = env.R_NN_filename



# Extract descriptive parameters of the system
rr_x = eta_x / 2  # radius of the partitions in the state-space
rr_u = eta_u / 2  # radius of the partitions in the input-space
dim_x = np.shape(X_range)[0]  # dimension of the state-space
dim_u = np.shape(U_range)[0]  # dimension of the input-space
discrete_sys_size = discrete_sys_size_gen()  # vector containing number of discrete pointsalong each dimension in the
state_space_size = discrete_sys_size[0:dim_x]
input_space_size = discrete_sys_size[dim_x:dim_x+dim_u]
# state and input spaces
num_dis_states = np.prod(discrete_sys_size[0:dim_x]).astype(int)  # size of the state-space
num_dis_inputs = np.prod(discrete_sys_size[dim_x:dim_x + dim_u]).astype(int)  # size of the input-space
num_state_inp_pairs = np.prod(discrete_sys_size).astype(int)  # number of state-input pairs
nn = 2 * (np.sum(discrete_sys_size[0:dim_x])+3*shift_no*dim_x)  # dimension of the vector at the output of the trained NN


# Run the function
make_keras_picklable()
# Load the model
NN_TS_forw = NN_structure_TS()
# Loads the weights
NN_TS_forw.load_weights(checkpoint_path_TS_forw)

# Compute the number of mismatched edges between the graphs generated by the analytical method and the NNs
start = time.time()
"""ray.init(_plasma_directory="/tmp", log_to_driver=False)
mismatched_edge_num_forw, num_total_transitions_forw, num_pairs_to_be_stored_forw, num_new_transitions_forw, list_of_state_input_pairs_to_be_stored_forw = edge_mismatch_counter(forw_inp_TS_filename, forw_out_TS_filename, num_state_inp_pairs, dim_x+dim_u, nn, NN_TS_forw, 1)
print("number of transitions in the forward system is", num_total_transitions_forw)
print("number of the mismatched edges for the forward transition system is", mismatched_edge_num_forw)
print("number of state input pairs to be stored is", num_pairs_to_be_stored_forw)
print("number of new transitions to be stored is", num_new_transitions_forw)
print("Edge mismatch rate for the forward transition system is", mismatched_edge_num_forw/num_total_transitions_forw)
print("The fraction of the state input pairs to be stored is", num_pairs_to_be_stored_forw/num_state_inp_pairs)"""
ray.shutdown()
# just to let the code run
#if num_pairs_to_be_stored_back == 0:
    #num_pairs_to_be_stored_back = 1
"""pairs_to_be_stored_list_forw_file = np.memmap(mismatch_list_forw_filename, dtype='float32', mode='w+', shape=(num_pairs_to_be_stored_forw, dim_x + dim_u), offset=0)
for i in range(num_pairs_to_be_stored_forw):
    pairs_to_be_stored_list_forw_file[i, :] = list_of_state_input_pairs_to_be_stored_forw[i]
pairs_to_be_stored_list_forw_file.flush()"""




# Load the model
NN_TS_back = NN_structure_TS()
# Loads the weights
NN_TS_back.load_weights(checkpoint_path_TS_back)

ray.init(_plasma_directory="/tmp", log_to_driver=False)
mismatched_edge_num_back, num_total_transitions_back, num_pairs_to_be_stored_back, num_new_transitions_back, list_of_state_input_pairs_to_be_stored_back = edge_mismatch_counter(back_inp_TS_filename, back_out_TS_filename, num_state_inp_pairs, dim_x+dim_u, nn, NN_TS_back, -1)
print("number of transitions in the backward system is", num_total_transitions_back)
print("number of the mismatched edges for the backward transition system is", mismatched_edge_num_back)
print("number of state input pairs to be stored is", num_pairs_to_be_stored_back)
print("number of new transitions to be stored is", num_new_transitions_back)
print("Edge mismatch rate for the backward transition system is", mismatched_edge_num_back/num_total_transitions_back)
print("The fraction of the state input pairs to be stored is", num_pairs_to_be_stored_back/num_state_inp_pairs)
ray.shutdown()

pairs_to_be_stored_list_back_file = np.memmap(mismatch_list_back_filename, dtype='float32', mode='w+', shape=(num_pairs_to_be_stored_back, dim_x + dim_u), offset=0)
for i in range(num_pairs_to_be_stored_back):
    pairs_to_be_stored_list_back_file[i, :] = list_of_state_input_pairs_to_be_stored_back[i]
pairs_to_be_stored_list_back_file.flush()
print("Execution time for approximation error computation is", time.time() - start)
