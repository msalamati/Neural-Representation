"""By running this code, the number of mismatched edges between graphs generated by the NNs and the analytical method
will be computed and saved."""
import os
import numpy as np
import math
import time
import copy
from functools import reduce
from operator import mul
import ray
import psutil
import gc
import tensorflow as tf
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.layers import Dense
from tensorflow.python.keras.layers import deserialize, serialize
from tensorflow.python.keras.saving import saving_utils
import env_pool

def unpack(model, training_config, weights):
    restored_model = deserialize(model)
    if training_config is not None:
        restored_model.compile(
            **saving_utils.compile_args_from_training_config(
                training_config
            )
        )
    restored_model.set_weights(weights)
    return restored_model

# Hotfix function
def make_keras_picklable():

    def __reduce__(self):
        model_metadata = saving_utils.model_metadata(self)
        training_config = model_metadata.get("training_config", None)
        model = serialize(self)
        weights = self.get_weights()
        return (unpack, (model, training_config, weights))

    cls = Model
    cls.__reduce__ = __reduce__


def auto_garbage_collect(pct=60.0):
    if psutil.virtual_memory().percent >= pct:
        gc.collect()


def discrete_sys_size_gen():
    """ This function computes a vector that contains number of
     discrete states for every dimension of state and input spaces."""
    discrete_sys_size = np.zeros(dim_x + dim_u)
    for ii in range(0, dim_x):
        discrete_sys_size[ii] = math.floor((X_range[ii, 1] - X_range[ii, 0] - eta_x[ii]) / eta_x[ii] + 1)
    for ii in range(dim_x, dim_x + dim_u):
        discrete_sys_size[ii] = math.floor(
            (U_range[ii - dim_x, 1] - U_range[ii - dim_x, 0] - eta_u[ii - dim_x]) / eta_u[ii - dim_x] + 1)
    return discrete_sys_size.astype(int)


def NN_structure_TS():
    """Create the model for estimating the transition system."""
    model = Sequential()
    model.add(Dense(40, input_dim=dim_x+dim_u, activation=tf.nn.relu))
    model.add(Dense(80, activation=tf.nn.tanh))
    model.add(Dense(160, activation=tf.nn.tanh))
    model.add(Dense(80, activation=tf.nn.tanh))
    model.add(Dense(35, activation=tf.nn.tanh))
    model.add(Dense(60, activation=tf.nn.tanh))
    model.add(Dense(dim_x, activation='linear'))
    return model


def NN_structure_GB():
    """Create the model for estimating the transition system."""
    model = Sequential()
    model.add(Dense(40, input_dim=dim_u, activation=tf.nn.relu))
    model.add(Dense(80, activation=tf.nn.tanh))
    model.add(Dense(160, activation=tf.nn.tanh))
    model.add(Dense(250, activation=tf.nn.tanh))
    model.add(Dense(160, activation=tf.nn.tanh))
    model.add(Dense(35, activation=tf.nn.tanh))
    model.add(Dense(60, activation=tf.nn.tanh))
    model.add(Dense(dim_x, activation='linear'))
    return model


def dataset_selector(X, offset, i, length):
    return ray.put(X[offset+i*length:min(offset+(i+1)*length, offset+length)])


def edge_mismatch_counter(inp_filename, out_filename_c, out_filename_r, num_samples, inp_dim, out_dim, safety_margin, NN_TS, NN_GB, FW_or_BW):
    x_tr = np.memmap(inp_filename, dtype='float32', mode='r', shape=(num_samples, inp_dim), offset=0)
    y_tr_c = np.memmap(out_filename_c, dtype='float32', mode='r', shape=(num_samples, out_dim), offset=0)
    y_tr_r = np.memmap(out_filename_r, dtype='float32', mode='r', shape=(num_samples, out_dim), offset=0)
    added_mismatch = 0
    added_reached = 0
    NN_TS_id = ray.put(NN_TS)
    NN_GB_id = ray.put(NN_GB)
    for step in range(num_samples // num_tasks_per_step+1):
        offset = step*num_tasks_per_step
        num_tasks_in_this_step = min(num_tasks_per_step, num_samples - step * num_tasks_per_step)
        new_mismatch_decoded = ray.get([single_mismatch_analyzer.remote(i,
                                                              ray.put(x_tr[offset+i*length:min(offset+(i+1)*length, offset+num_tasks_in_this_step)]),
                                                              ray.put(y_tr_c[offset+i*length:min(offset+(i+1)*length, offset+num_tasks_in_this_step)]),
                                                              ray.put(y_tr_r[offset + i * length:min(offset + (i + 1) * length, offset + num_tasks_in_this_step)]),
                                                              NN_TS_id, NN_GB_id, safety_margin,
                                                              length, num_tasks_in_this_step)[0]
                              for i in range(0, num_tasks_in_this_step // length+1)])
        new_added_decoded = ray.get([single_mismatch_analyzer.remote(i,
                                                          ray.put(x_tr[offset+i*length:min(offset+(i+1)*length, offset+num_tasks_in_this_step)]),
                                                          ray.put(y_tr_c[offset+i*length:min(offset+(i+1)*length, offset+num_tasks_in_this_step)]),
                                                          ray.put(y_tr_r[offset + i * length:min(offset + (i + 1) * length, offset + num_tasks_in_this_step)]),
                                                          NN_TS_id, NN_GB_id, safety_margin,
                                                          length, num_tasks_in_this_step)[1]
                              for i in range(0, num_tasks_in_this_step // length+1)])
        auto_garbage_collect()
        added_mismatch += np.sum(new_mismatch_decoded)
        added_reached += np.sum(new_added_decoded)
        auto_garbage_collect()
        del new_mismatch_decoded
        del new_added_decoded
        """
        # the equivalent non-blocking implementation with ray.wait:
        start = time.time()
        to_be_run = [single_mismatch_analyzer.remote(i,
                                                  ray.put(x_tr[offset+i*length:min(offset+(i+1)*length, offset+num_tasks_in_this_step)]),
                                                  ray.put(y_tr[offset+i*length:min(offset+(i+1)*length, offset+num_tasks_in_this_step)]),
                                                  NN_TS_id, NN_GB_id, safety_margin,
                                                  GB_set[(offset+i*length)//num_dis_states: (offset+i*length)//num_dis_states+1],
                                                  length, num_tasks_in_this_step)[0]
                              for i in range(0, num_tasks_in_this_step // length+1)]
        while len(to_be_run):
            done, to_be_run = ray.wait(to_be_run)
            added_mismatch += np.sum(ray.get(done[0]))
        to_be_run = [single_mismatch_analyzer.remote(i,
                                                          ray.put(x_tr[offset+i*length:min(offset+(i+1)*length, offset+num_tasks_in_this_step)]),
                                                          ray.put(y_tr[offset+i*length:min(offset+(i+1)*length, offset+num_tasks_in_this_step)]),
                                                          NN_TS_id, NN_GB_id, safety_margin,
                                                          GB_set[(offset+i*length)//num_dis_states: (offset+i*length)//num_dis_states+1],
                                                          length, num_tasks_in_this_step)[1]
                              for i in range(0, num_tasks_in_this_step // length+1)]
        while len(to_be_run):
            done, to_be_run = ray.wait(to_be_run)
            added_reached += np.sum(ray.get(done[0]))
        print('here is the time', time.time()-start)"""
    return added_mismatch, added_reached

@ray.remote(num_returns = 2)
def single_mismatch_analyzer(i, xx, yy_c, yy_r, NN_TS, NN_GB, safety_margin, length, num_tasks_in_this_step):
    length_for_this_step = min(length, num_tasks_in_this_step - i * length)
    added_mismatch = 0
    added_reached = 0
    e_analytical = 0
    e_NN = safety_margin
    for _ in range(length_for_this_step):
        s1 = xx[_, :]
        inp = s1[dim_x:dim_x + dim_u]
        # Finding discrete set of states corresponding to the continuous disc (for the analytical solution)
        s2 = yy_c[_, :]  # np.memmap(out_filename, dtype='float32', mode='r+', shape=(1, out_dim), offset=int(_*(dim_x)*32/8))#
        # note that reachable set includes reachable states under all of the inputs (reachable set is not computed for each pair of state-input)
        r_analytical = yy_r[_, :]  # slightly wrong???
        ind_set_analytical = update_reachable_set(e_analytical, s2, r_analytical)
        ind_tuple_analytical = [tuple(item) for item in ind_set_analytical]
        """for ind in range(len(ind_set_analytical)):
            ind_tuple = tuple(ind_set_analytical[ind])
            R_analytical[ind_tuple] = 1"""
        # Finding discrete set of states corresponding to the continuous disc (for the solution by NN)
        s2_NN = NN_TS(np.array([s1]))
        r_NN = NN_GB(np.array([s1]))
        ind_set_NN = update_reachable_set(e_NN, np.squeeze(s2_NN.numpy()), r_NN)
        ind_tuple_NN = [tuple(item) for item in ind_set_NN]
        """for ind in range(len(ind_set_NN)):
            ind_tuple = tuple(ind_set_NN[ind])
            R_NN[ind_tuple] = 1"""
        added_mismatch += len(set(ind_tuple_NN).difference(set(ind_tuple_analytical)))
        added_reached += len(set(ind_tuple_analytical))
        print(added_mismatch)
        # check being sound
        """ind_anal_tuple = [tuple(item) for item in ind_set_analytical]
        ind_NN_tuple = [tuple(item) for item in ind_set_NN]
        print(set(ind_anal_tuple).difference(set(ind_NN_tuple)))"""
    return [added_mismatch, added_reached]


def update_reachable_set(err, s2, radii):
    """Finding discrete set of states corresponding to the continuous disc (for the analytical solution)"""
    reach_low_vec_discrete_analytical = np.squeeze(np.minimum(tuple(discrete_sys_size[0:dim_x])-np.ones(dim_x), np.maximum(np.zeros(dim_x), np.floor((s2-radii-err-X_range[:, 0])/np.squeeze(eta_x)))))
    reach_high_vec_discrete_analytical = np.squeeze(np.minimum(tuple(discrete_sys_size[0:dim_x])-np.ones(dim_x), np.maximum(np.ones(dim_x), np.floor((s2+radii+err-X_range[:, 0])/np.squeeze(eta_x)))))
    reach_ind_range = np.zeros((dim_x, 2))
    for ind in range(dim_x):
        reach_ind_range[ind, :] = [reach_low_vec_discrete_analytical[ind], reach_high_vec_discrete_analytical[ind]+1] # Adding 1 is necessary for the next step

    ranges = reach_ind_range.astype(int).tolist()
    operations = reduce(mul, (p[1] - p[0] for p in ranges)) - 1  # No. of reached states - 1
    result = [ii[0] for ii in ranges]  # The first reached state
    pos = len(ranges) - 1  # Set the pointer at the last dimension
    increments = 0
    ind_set = [copy.copy(result)]  # Copying value of the first reached state into ind_set
    while increments < operations:
        if result[pos] == ranges[pos][1] - 1:
            result[pos] = ranges[pos][0]
            pos -= 1  # Set the pointer to the previous dimension
        else:
            result[pos] += 1
            increments += 1
            pos = len(ranges) - 1  # Increment the innermost loop and set the pointer at the last dimension
            ind_set.append(copy.copy(result))

    return ind_set


# Setting the parameters
env = env_pool.tora()

X_range = env.X_range  # state-space
U_range = env.U_range  # input space
sample_time = env.sample_time  # sampling time in seconds
eta_x = env.eta_x  # state-space discretization size
eta_u = env.eta_u  # input-space discretization size
# parallelization parameters
length = env.length
num_tasks_per_step = env.num_tasks_per_step
# defining filenames for saving the transition system
forw_sub_inp_TS_filename = env.forw_inp_TS_filename
forw_sub_out_TS_c_filename = env.forw_out_TS_c_filename
forw_sub_out_TS_r_filename = env.forw_out_TS_r_filename
back_inp_TS_filename = env.back_inp_TS_filename
back_out_TS_c_filename = env.back_out_TS_c_filename
back_out_TS_r_filename = env.back_out_TS_r_filename
# defining paths for saving the trained NNs
checkpoint_path_TS_forw = env.checkpoint_path_TS_forw
checkpoint_path_TS_back = env.checkpoint_path_TS_back
checkpoint_path_GB_forw = env.checkpoint_path_GB_forw
checkpoint_path_GB_back = env.checkpoint_path_GB_back
# defining filenames for saving the approximation error vector
e_vec_TS_forw_filename = env.e_vec_TS_forw_filename
e_vec_TS_back_filename = env.e_vec_TS_back_filename
e_vec_GB_forw_filename = env.e_vec_GB_forw_filename
e_vec_GB_back_filename = env.e_vec_GB_back_filename
# defining filenames for saving the safety margins
safety_margin_FW_filename = env.safety_margin_FW_filename
safety_margin_BW_filename = env.safety_margin_BW_filename



# Extract descriptive parameters of the system
rr_x = eta_x / 2  # radius of the partitions in the state-space
rr_u = eta_u / 2  # radius of the partitions in the input-space
dim_x = np.shape(X_range)[0]  # dimension of the state-space
dim_u = np.shape(U_range)[0]  # dimension of the input-space
discrete_sys_size = discrete_sys_size_gen()  # vector containing number of discrete pointsalong each dimension in the
# state and input spaces
num_dis_states = np.prod(discrete_sys_size[0:dim_x]).astype(int)  # size of the state-space
num_dis_inputs = np.prod(discrete_sys_size[dim_x:dim_x + dim_u]).astype(int)  # size of the input-space
num_state_inp_pairs = np.prod(discrete_sys_size).astype(int)  # number of state-input pairs

# Run the function
make_keras_picklable()
# Load the model
NN_TS_forw = NN_structure_TS()
NN_TS_back = NN_structure_TS()
NN_GB_forw = NN_structure_TS()
NN_GB_back = NN_structure_TS()
# Loads the weights
NN_TS_forw.load_weights(checkpoint_path_TS_forw)
NN_TS_back.load_weights(checkpoint_path_TS_back)

NN_GB_forw.load_weights(checkpoint_path_GB_forw)
NN_GB_back.load_weights(checkpoint_path_GB_back)
# Loading the computed approximation error
safety_margin_forw = np.load(safety_margin_FW_filename)
safety_margin_back = np.load(safety_margin_BW_filename)

# Compute the number of mismatched edges between the graphs generated by the analytical method and the NNs
start = time.time()
ray.init(_plasma_directory="/tmp", log_to_driver=False)
mismatched_edge_num_forw, num_total_transitions_forw = edge_mismatch_counter(forw_sub_inp_TS_filename, forw_sub_out_TS_c_filename, forw_sub_out_TS_r_filename, num_state_inp_pairs, dim_x+dim_u, dim_x, safety_margin_forw, NN_TS_forw, NN_GB_forw, 1)
print("number of transitions in the forward system is", num_total_transitions_forw)
print("Edge mismatch rate for the forward transition system is", mismatched_edge_num_forw/num_total_transitions_forw)
ray.shutdown()
ray.init(_plasma_directory="/tmp", log_to_driver=False)
mismatched_edge_num_back, num_total_transitions_back = edge_mismatch_counter(back_inp_TS_filename, back_out_TS_c_filename, back_out_TS_r_filename, num_state_inp_pairs, dim_x+dim_u, dim_x, safety_margin_back, NN_TS_back, NN_GB_back, -1)
print("number of transitions in the backward system is", num_total_transitions_back)
print("Edge mismatch rate for the backward transition system is", mismatched_edge_num_back/num_total_transitions_back)
ray.shutdown()
print("Execution time for approximation error computation is", time.time() - start)